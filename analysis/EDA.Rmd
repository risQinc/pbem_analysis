---
title: "Exploratory Data Analysis"
output:
  pdf_document: default
  word_document: default
---

```{r, error=FALSE, warning=FALSE, message=FALSE}
library(data.table)
library(lubridate)
library(tidyverse)
library(ggplot2)
library(dplyr)
library(zoo)
```

We essentially have 6 data sources that we want to explore / validate. The first data source is the tide data which Carling has compiled via TideGauge_DailyData.rds. To start, we focused only on the Atlantic City location since this is the source that is referenced in the Meyer paper. In the future, we may consider replacing the Atlantic City data with Cape May data since it is closer to the ocean. As far as I know, there are no plots or references in the Meyer paper that we can use to validate whether the tide data we are working with is reasonably similar to the data they were using.

# 1. Tide Data

-- Re-download the tide data and blend actual reedy island tide daily avgs with atlantic city tide daily avgs * some factor

```{r cars}
tide_data <- readRDS('../data/raw/TideGauge_DailyData.rds')
tide_data = as.data.table(tide_data)

#Time Range 1: November 1, 1964 to November 1, 1966
#Time Range 2: November 1997 to November 1999)

relevant_tide_dat = tide_data[, c('ReedyPoint.date', 'ReedyPoint.sea_level', 'AtlanticCity.date', 'AtlanticCity.sea_level')]

# cape may sealevel
# fort pulasaki sealevel
# springmaid pier sealevel
# charleston
relevant_tide_dat$AtlanticCity.date = as.Date(relevant_tide_dat$AtlanticCity.date)
relevant_tide_dat$ReedyPoint.date = as.Date(relevant_tide_dat$ReedyPoint.date)
```

```{r}
atlantic = relevant_tide_dat[, c('AtlanticCity.date', 'AtlanticCity.sea_level')] %>% 
  group_by(AtlanticCity.date) %>% 
  summarise(atl_sl = mean(AtlanticCity.sea_level))

reedy_sl = relevant_tide_dat[, c('ReedyPoint.date', 'ReedyPoint.sea_level')] %>% 
  group_by(ReedyPoint.date) %>% 
  summarise(reedy_sl = mean(ReedyPoint.sea_level))


setnames(atlantic, 'AtlanticCity.date', 'date')
setnames(reedy_sl, 'ReedyPoint.date', 'date')

compare = merge(reedy_sl, atlantic)


# TIDE TS Plot
ggplot(compare, aes(x = reedy_sl, y = atl_sl))+
  geom_point()+
  geom_smooth(method = 'lm')+
  ggtitle('Reedy Island vs Atlantic City Avg Daily Tides')
```

```{r}
lm = lm(reedy_sl ~ atl_sl, data = compare)
summary(lm)
```

The final tide data file we will use for our purposes will be "extended reedy"

```{r}
atlantic <- atlantic %>% mutate(reedy_sl = atl_sl*.9 - 27.182060)
approx_reedy = atlantic %>% filter(date < '1979-07-01')

extended_reedy = as.data.table(rbind(approx_reedy, atlantic))
extended_reedy[, approximated := ifelse(date < '1979-07-01', 'proxy', 'actual')]

ggplot(extended_reedy, aes(x = date, y = reedy_sl, color = approximated))+
  geom_point(size = .2)+
  ggtitle('Extended Reedy Sea Levels Using Atlantic City Proxy')
```
```{r}
extended_reedy[, water_level := (reedy_sl - 49.229)/12]
ggplot(extended_reedy, aes(x = date, y = water_level))+
  geom_point(size = .2)+
  ggtitle('Water Level Data, Mean Adjusted')
```

# DISCHARGE (INFLOW) DATA

We have two sources of discharge (aka streamflow aka inflow) data: Delaware River and Schulkill River. The Delware river data contains discharge data in cubic feet per second. Figure 2 in the Meyer paper plots average inflows per month at both locations. From an initial look at our data compared to the Meyer data, it appears that the seasonal patterns are non-trivially different. Our data suggests peak inflows in March while figure 2 suggests peak inflows in June. It is unclear exactly which time period the Meyer authors used to contruct Figure 2.

Next Steps: Hopefully we can find a way to align our values with what we see in Figure 2, but I don't have any ideas on how to do this other than trying to plot different time frames with trial and error?

## 2. Delaware River at Trenton

Load in the text file as it appears in box. Calculate the % of missing values per each column to get a sense of where the useful data is. In most of these txt files there are 40+ columns with only 5 or 6 columns worth of filled in data values. Once we figure out the index of the columns with data, we open the txt file and match the codes at those indices with the descriptions to figure out what each filled-in column represents. It appears that only columns 1, 2, 3, 28, and 29 contain non-null data. According to the codes in this text file, those column names correspond to 'agency_cd', 'site_no',	'date', 'Discharge, cubic feet per second (Mean)', and a "cd" value...). Next we rename the columns so that we can extract the subset of useful data.
```{r pressure, echo=FALSE, error=FALSE, warning=FALSE, message=FALSE}
dr = read_delim("../data/raw/del_riv_trent.txt", delim = "\t", skip = 68, col_names = FALSE)
```



```{r, warning=FALSE, message=FALSE}
colnames(dr) <- c('agency_cd', 'site_no',	'date','missing_4', 'missing_5', 'm6', 'm7', 'm8', 'm9', 'm10', 'm11', 'm12', 'm13', 'm14', 'm15', 'm16', 'm17', 'm18', 'm19', 'm20', 'm21', 'm22', 'm23', 'm24', 'm25', 'm26', 'm27', 'avg_discharge_cfps', 'code', 'm30', 'm31', 'm32', 'm33', 'm34', 'm35', 'm36', 'm37', 'm38', 'm39', 'm40', 'm41', 'm42', 'm43', 'm44', 'm45', 'm46', 'm47', 'm48', 'm49', 'm50', 'm51', 'm52', 'm53', 'm54', 'm55', 'm56', 'm57', 'm58', 'm59', 'm60', 'm61', 'm62', 'm63', 'm64', 'm65', 'm66', 'm67', 'm68', 'm69', 'm70', 'm71', 'm72', 'm73', 'm74', 'm75')

dr_clean = as.data.table(dr[, c('agency_cd', 'site_no',	'date', 'avg_discharge_cfps')])
head(dr_clean)
```

```{r, warning=FALSE, message=FALSE}
dr_clean[, month := month(date)]
ts_dr_flows = dr_clean %>% group_by(month) %>%
  summarise(avg_inflow = mean(avg_discharge_cfps))

ggplot(ts_dr_flows, aes(x = month, y = avg_inflow*0.0283168))+
  geom_bar(stat = 'identity', position = 'dodge')+
  ylim(0,600)+
  ggtitle('Average of Delaware River @ Trenton, 1950 - 2020')

```


```{r, warning=FALSE, message=FALSE}
ts_dr_flows = dr_clean[(date <= '1999-11-01' & date >= '1997-11-01' ) | 
                                (date >= '1964-11-01' & date <= '1966-11-01')] %>% group_by(month) %>%
  summarise(avg_inflow = mean(avg_discharge_cfps))

ggplot(ts_dr_flows, aes(x = month, y = avg_inflow*0.0283168))+
  geom_bar(stat = 'identity', position = 'dodge')+
  ylim(0,600)+
  ggtitle('Average of Delaware River @ Trenton, 1965 to 1966 & 1998 - 1999')
```

Neither of these plots show a similar seasonal pattern to what is shown in the Meyer paper.


## 3. Schuylkill River

Repeat the process from the Delaware river on the schuylkill river data. This 

```{r, warning=FALSE, message=FALSE}
sr <-  read_delim("../data/raw/skill_riv.txt", delim = "\t", skip = 50, col_names = FALSE)  
```


```{r, warning=FALSE, message=FALSE}
colnames(sr) <- c('agency_cd', 'site_no',	'date',  'avg_discharge_cfps', 'code', 'max_sc_mc_sie_p_cm_25c', 'na2', 'min_sc_mc_sie_p_cm_25c', 'na3', 'avg_sc_mc_sie_p_cm_25c', 'na4', 'max_dis_o2', 'na5', 'min_dis_o2', 'na6', 'avg_dis_o2', 'na7', 'max_temp_c2', 'na8', 'min_temp_c2', 'na9', 'avg_temp_c2', 'na10', 'max_ph', 'na11', 'min_ph', 'na12', 'avg_sus_sed_conc', 'na13', 'avg_sus_sed_discharge', 'na14', 'max_temp_f', 'na15', 'min_temp_f', 'na16', 'avg_temp_f', 'na17', 'avg_temp_c', 'na18', 'max_temp_c', 'na19', 'min_temp_c', 'na20')
sr_clean = as.data.table(sr[, c('agency_cd', 'site_no',	'date',  'avg_discharge_cfps', 'code')])
sr_clean[, month := month(date)]

# our peak raes are march, theirs are in june
# possible difference in data aggregation?
ts_sr_flows = sr_clean %>% group_by(month) %>%
  summarise(avg_inflow = mean(avg_discharge_cfps))

ggplot(ts_sr_flows, aes(x = month, y = avg_inflow*0.0283168))+
  geom_bar(stat = 'identity', position = 'dodge')+
  ylim(0,600)+
  ggtitle('Average of Schuylkill, 1950 - 2020')

```

```{r, warning=FALSE, message=FALSE}

# plotting inflows only during periods of interest
ts_dr_flows = dr_clean[(date <= '1999-11-01' & date >= '1997-11-01' ) | (date >= '1964-11-01' & date <= '1966-11-01')] %>% group_by(month) %>% summarise(avg_inflow = mean(avg_discharge_cfps))

ts_sr_flows = sr_clean[(date <= '1999-11-01' & date >= '1997-11-01' ) | (date >= '1964-11-01' & date <= '1966-11-01')] %>% group_by(month) %>% summarise(avg_inflow = mean(avg_discharge_cfps))

#ts_dr_flows = dr_clean %>% group_by(month) %>% summarise(avg_inflow = mean(avg_discharge_cfps))
#ts_sr_flows = sr_clean %>% group_by(month) %>% summarise(avg_inflow = mean(avg_discharge_cfps))

ts_sr_flows = ts_sr_flows %>% mutate(river = 'schuylkill')
ts_dr_flows = ts_dr_flows %>% mutate(river = 'delaware')

flows = rbind(ts_sr_flows, ts_dr_flows)


ggplot(flows, aes(x = month, y = avg_inflow*0.0283168, fill = river))+
  geom_bar(stat = 'identity', position = 'dodge')+
  ylim(0,600)+
 #ggtitle('Average of Monthly Flows, 1965 to 1966 & 1998 - 1999')
ggtitle('Average of Monthly Flows, 1950 - 2020')

```

This plot essentially recreates Figure 2 (minus PST model inflows). The ratio of inflow at Delaware vs Schuylkill is consistent with what we see in the Meyer paper, but our data looks more like an inverse bell curve than the normal curve we were expecting?

*Next Steps: Ideally we want to figure out why our inflow data doesn't match with what is shown in Figure 2 of the Meyer paper.*

# SC DATA

## 4. Chester
```{r, results="hide", warning=FALSE, message=FALSE}
chester <-  read_delim("../data/raw/Chester_SC.txt", delim = "\t", skip = 32, col_names = FALSE)  
```

According to the codes I see in the txt file, X4 corresponds to  max SC; X6 is min SC, X8 is average SC but it is all missing

```{r, warning=FALSE, message=FALSE}
colnames(chester) <- c('agency_cd', 'site_no',	'date',  'max_sc', 'code', 'min_sc', 'na2', 'mean_sc', 'code2')
chester_clean = as.data.table(chester[, c('agency_cd', 'site_no',	'date',  'max_sc', 'min_sc', 'mean_sc')])
head(chester_clean)
```

```{r, warning=FALSE, message=FALSE}
chester_clean = as.data.table(chester_clean)[, time_range := ifelse( (date <= '1999-11-01' & date >= '1997-11-01') , '1997 - 1999', 
                                                             ifelse( (date >= '1964-11-01' & date <= '1966-11-01'), '1965 - 1966', 'non-relevant'))]


chester_melt = melt(data = chester_clean, id.vars = c("agency_cd", "site_no", 'date', 'time_range'), measure.vars = c("max_sc", "min_sc", 'mean_sc'))
setnames(chester_melt, 'variable', 'metric')
setnames(chester_melt, 'value', 'sc')

ggplot(chester_melt[time_range != 'non-relevant' & metric == 'mean_sc'], aes(x = date, y = sc, color = metric))+
  facet_wrap(~time_range, scales = "free_x", switch = 'x')+
  geom_line()+
  ggtitle('SC at Chester')
```

Chester SC values line up nicely with Fig 2 in Meyer paper.                          


## 5. Reedy Island
```{r, warning=FALSE, message=FALSE}
reedy <-  read_delim("../data/raw/reedy_island_sc.txt", delim = "\t", skip = 50, col_names = FALSE)  
```

Column 4 is max SC; column 6 is min SC; column 8 is average SC

```{r, warning=FALSE, message=FALSE}
colnames(reedy) <- c('agency_cd', 'site_no',	'date',  'max_sc', 'code', 'min_sc', 'code2', 'mean_sc', 'na3', 'avg_sc_mc_sie_p_cm_25c', 'na4', 'max_dis_o2', 'na5', 'min_dis_o2', 'na6', 'avg_dis_o2', 'na7', 'max_temp_c2', 'na8', 'min_temp_c2', 'na9', 'avg_temp_c2', 'na10', 'max_ph', 'na11', 'min_ph', 'na12', 'avg_sus_sed_conc', 'na13', 'avg_sus_sed_discharge', 'na14', 'max_temp_f', 'na15', 'min_temp_f', 'na16')
reedy_clean = as.data.table(reedy[, c('agency_cd', 'site_no',	'date',  'max_sc', 'min_sc', 'mean_sc')])
head(reedy_clean)

```

```{r, warning=FALSE, message=FALSE}
reedy_clean = as.data.table(reedy)[, time_range := ifelse( (date <= '1999-11-01' & date >= '1997-11-01') , '1997 - 1999', 
                                                             ifelse( (date >= '1964-11-01' & date <= '1966-11-01'), '1965 - 1966', 'non-relevant'))]


reedy_melt = melt(data = reedy_clean, id.vars = c("agency_cd", "site_no", 'date', 'time_range'), measure.vars = c("max_sc", "min_sc", 'mean_sc'))
setnames(reedy_melt, 'variable', 'metric')
setnames(reedy_melt, 'value', 'sc')

ggplot(reedy_melt[time_range != 'non-relevant' & metric == 'mean_sc'], aes(x = date, y = sc, color = metric))+
  facet_wrap(~time_range, scales = "free_x", switch = 'x')+
  geom_line()+
  ggtitle('SC at Reedy Island')
```

This seems like a reasonable comparison to what we see in the Meyer paper.


## 6. Ben Franklin Bridge 

```{r, warning=FALSE, message=FALSE}
bfb <- read_delim("../data/raw/BenFranklinBridge_SC.txt", delim = "\t", skip = 32, col_names = FALSE)
```


```{r}
colnames(bfb) <- c('agency_cd', 'site_no',	'date',  'max_sc', 'code', 'min_sc', 'na2', 'mean_sc', 'code2')
```

```{r}
bfb_clean = as.data.table(bfb)[, time_range := ifelse( (date <= '1999-11-01' & date >= '1997-11-01') , '1997 - 1999', 
                                                             ifelse( (date >= '1964-11-01' & date <= '1966-11-01'), '1965 - 1966', 'non-relevant'))]


bfb_melt = melt(data = bfb_clean, id.vars = c("agency_cd", "site_no", 'date', 'time_range'), measure.vars = c("max_sc", "min_sc", 'mean_sc'))
setnames(bfb_melt, 'variable', 'metric')
setnames(bfb_melt, 'value', 'sc')

ggplot(bfb_melt[time_range != 'non-relevant' & metric == 'mean_sc'], aes(x = date, y = sc, color = metric))+
  facet_wrap(~time_range, scales = "free_x", switch = 'x')+
  geom_line()+
  ggtitle('SC at Ben Franklin Bridge')
```


# Build Training Data
```{r}
# data sets to merge: 
# tide: [extended_reedy]
#inflows: [dr_clean, sr_clean]
#sc: [chester_clean, reedy_clean, bfb_clean])

# INFLOWS
dr <- dr_clean %>% mutate(inflow = avg_discharge_cfps*0.0283168, location = 'del_bfb')
sr <- sr_clean %>% mutate(inflow = avg_discharge_cfps*0.0283168, location = 'schu_chester')

inflows <- rbind(dr[, c('date', 'inflow', 'location')], sr[, c('date', 'inflow', 'location')])

# SC
chester <- chester_clean %>% mutate(location = 'schu_chester')
reedy <- reedy_clean %>% mutate(location = 'reedy')
bfb <- bfb_clean %>% mutate(location = 'del_bfb')


sc = rbind(chester[, c('date', 'location', 'mean_sc')], reedy[, c('date', 'location', 'mean_sc')], bfb[, c('date', 'location', 'mean_sc')])
```


Jane's Form Training Data
```{r}
training_data = merge(inflows, sc, all.y = TRUE)
training_data = merge(training_data, extended_reedy[, c('date', 'reedy_sl')], by = 'date', all.x = TRUE)
head(training_data)
```

Explore correlations
```{r}
#library(corrplot)
#training_data[, month := month(date)]
reedy = training_data %>% filter(location == 'reedy') %>% select( 'mean_sc', 'reedy_sl', 'month')
bfb = training_data %>% filter(location == 'del_bfb') %>% select( 'mean_sc', 'reedy_sl', 'month', 'inflow')
reedy = na.omit(reedy)
bfb = na.omit(bfb)
reedy.cor = cor(reedy)
bfb = cor(bfb)
corrplot(df.cor)
cor(reedy$mean_sc, reedy$reedy_sl)
cor(bfb$mean_sc, bfb$reedy_sl)
```


Visualize Training Data

```{r}
ggplot(training_data, aes(date, inflow))+
  geom_point(size = .2)+
  facet_wrap(~location, scales = 'free_y', switch = 'y')+
  ggtitle('All Time Inflow Values')
```


```{r}
ggplot(training_data, aes(date, mean_sc))+
  geom_point(size = .2)+
  facet_wrap(~location, , scales = "free_y", switch = 'y')+
  ggtitle("All Time Mean SC Values")+
  theme(axis.text.x = element_text(angle = 90))
```

```{r}
ggplot(training_data, aes(date, reedy_sl))+
  geom_point()+
  ggtitle('All Time Tide Levels')
```


```{r}
write.csv(training_data, '../data/processed/training_data.csv')
```

